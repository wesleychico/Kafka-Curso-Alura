[2020-03-22 15:08:08,853] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(ECOMMERCE_NEW_ORDER-1, ECOMMERCE_NEW_ORDER-2) (kafka.server.ReplicaFetcherManager)
[2020-03-22 15:08:08,859] INFO [Log partition=ECOMMERCE_NEW_ORDER-1, dir=/home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-22 15:08:08,860] INFO [Log partition=ECOMMERCE_NEW_ORDER-1, dir=/home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-22 15:08:08,860] INFO Created log for partition ECOMMERCE_NEW_ORDER-1 in /home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka/ECOMMERCE_NEW_ORDER-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-22 15:08:08,861] INFO [Partition ECOMMERCE_NEW_ORDER-1 broker=0] No checkpointed highwatermark is found for partition ECOMMERCE_NEW_ORDER-1 (kafka.cluster.Partition)
[2020-03-22 15:08:08,861] INFO [Partition ECOMMERCE_NEW_ORDER-1 broker=0] Log loaded for partition ECOMMERCE_NEW_ORDER-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-22 15:08:08,861] INFO [Partition ECOMMERCE_NEW_ORDER-1 broker=0] ECOMMERCE_NEW_ORDER-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-22 15:08:08,867] INFO [Log partition=ECOMMERCE_NEW_ORDER-2, dir=/home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-22 15:08:08,867] INFO [Log partition=ECOMMERCE_NEW_ORDER-2, dir=/home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-22 15:08:08,868] INFO Created log for partition ECOMMERCE_NEW_ORDER-2 in /home/chico/Documentos/Projetos/kafka_2.12-2.4.1/data/kafka/ECOMMERCE_NEW_ORDER-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-22 15:08:08,868] INFO [Partition ECOMMERCE_NEW_ORDER-2 broker=0] No checkpointed highwatermark is found for partition ECOMMERCE_NEW_ORDER-2 (kafka.cluster.Partition)
[2020-03-22 15:08:08,868] INFO [Partition ECOMMERCE_NEW_ORDER-2 broker=0] Log loaded for partition ECOMMERCE_NEW_ORDER-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-22 15:08:08,868] INFO [Partition ECOMMERCE_NEW_ORDER-2 broker=0] ECOMMERCE_NEW_ORDER-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-22 15:09:49,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-22 15:19:49,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-22 15:29:49,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-22 15:39:49,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-22 15:47:34,060] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-22 15:47:34,064] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-22 15:47:34,072] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-22 15:47:34,182] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-22 15:47:34,392] WARN Session 0x10000079b750000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Conex達o fechada pela outra ponta
	at java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2020-03-22 15:47:34,495] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-22 15:47:34,496] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-22 15:47:35,554] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-22 15:47:35,554] INFO Socket error occurred: localhost/127.0.0.1:2181: Conex達o recusada (org.apache.zookeeper.ClientCnxn)
[2020-03-22 15:47:35,655] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-22 15:47:36,843] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-22 15:47:36,843] INFO Socket error occurred: localhost/127.0.0.1:2181: Conex達o recusada (org.apache.zookeeper.ClientCnxn)
[2020-03-22 15:47:38,061] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-22 15:47:38,062] INFO Socket error occurred: localhost/127.0.0.1:2181: Conex達o recusada (org.apache.zookeeper.ClientCnxn)
